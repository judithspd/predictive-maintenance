{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "still-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "engaged-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"statistics_10_train.csv\" , sep = ',')\n",
    "df_test = pd.read_csv(\"statistics_10_test.csv\" , sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "variable-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['Kurtosis', 'Impulse factor', 'RMS', 'Margin factor', 'Skewness',\n",
    "               'Shape factor', 'Peak to peak', 'Crest factor']].values\n",
    "y_train = df_train['Tipo'].values\n",
    "X_test = df_test[['Kurtosis', 'Impulse factor', 'RMS', 'Margin factor', 'Skewness',\n",
    "               'Shape factor', 'Peak to peak', 'Crest factor']].values\n",
    "y_test = df_test['Tipo'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concerned-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, atpe, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "from hyperopt import hp\n",
    "from hyperopt import space_eval\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def lgb_clas(self, para):\n",
    "        clf = lgb.LGBMClassifier(**para['clas_params'])\n",
    "        return self.train_clf(clf, para)\n",
    "    \n",
    "    def train_clf(self, clf, para):\n",
    "        clf.fit(self.x_train, self.y_train,\n",
    "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)], \n",
    "                verbose = False, early_stopping_rounds = 20)\n",
    "        pred = clf.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "happy-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lgb_clas_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.001, 0.5, 0.001)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 10, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(0, 10, 1)),\n",
    "    'min_data_in_leaf': hp.choice('min_data_in_leaf', np.arange(0, 10, 1)),\n",
    "    'subsample':        hp.choice('subsample',        np.arange(0.1, 1, 0.05)),\n",
    "    'n_estimators':     hp.choice('n_estimators',     np.arange(10, 200, 10, dtype=int)),\n",
    "    'num_leaves':       hp.choice('num_leaves',       np.arange(5, 51, 1, dtype=int)),\n",
    "    }\n",
    "\n",
    "lgb_para = dict()\n",
    "lgb_para['clas_params'] = lgb_clas_params\n",
    "lgb_para['loss_func' ] = lambda y, pred: accuracy_score(y, pred)# squared = False)\n",
    "lgb_para[\"max_evals\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "little-sympathy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 100/100 [01:59<00:00,  1.19s/trial, best loss: 0.8333333333333334]\n"
     ]
    }
   ],
   "source": [
    "# Optimización \n",
    "obj = HPOpt(X_train, X_test, y_train, y_test)\n",
    "\n",
    "lgb_opt = obj.process(fn_name='lgb_clas', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=lgb_para[\"max_evals\"])\n",
    "parametros = space_eval(lgb_clas_params, lgb_opt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "quality-teddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.342, max_depth=9, min_child_weight=0,\n",
       "               min_data_in_leaf=7, n_estimators=90, num_leaves=33,\n",
       "               subsample=0.15000000000000002)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.set_params(**parametros) \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "willing-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  3  0]\n",
      " [ 0 30  0]\n",
      " [ 0  1 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Inner       1.00      0.90      0.95        30\n",
      "       Outer       0.88      1.00      0.94        30\n",
      "        Sano       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.96        90\n",
      "   macro avg       0.96      0.96      0.96        90\n",
      "weighted avg       0.96      0.96      0.96        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sunset-worcester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29  1  0]\n",
      " [ 0 30  0]\n",
      " [ 0  3 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Inner       1.00      0.97      0.98        30\n",
      "       Outer       0.88      1.00      0.94        30\n",
      "     Healthy       1.00      0.90      0.95        30\n",
      "\n",
      "    accuracy                           0.96        90\n",
      "   macro avg       0.96      0.96      0.96        90\n",
      "weighted avg       0.96      0.96      0.96        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(n_estimators = 100, learning_rate = 0.01, min_data_in_leaf = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "target_names = ['Inner', 'Outer', 'Healthy']\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "emotional-jerusalem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90  0  0]\n",
      " [ 0 90  0]\n",
      " [ 0  0 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Inner       1.00      1.00      1.00        90\n",
      "       Outer       1.00      1.00      1.00        90\n",
      "     Healthy       1.00      1.00      1.00        90\n",
      "\n",
      "    accuracy                           1.00       270\n",
      "   macro avg       1.00      1.00      1.00       270\n",
      "weighted avg       1.00      1.00      1.00       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train = clf.predict(X_train)\n",
    "print(confusion_matrix(y_train, pred_train))\n",
    "print(classification_report(y_train, pred_train, target_names = target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
